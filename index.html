<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zhengxiao Han</title>

    <meta name="author" content="Zhengxiao Han">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Zhengxiao Han
                  </p>
                  <p>I'm a Visiting Researcher at 
                    <a href="https://cfcs.pku.edu.cn/english/">Center on Frontiers of Computing Studies, Peking University</a>, 
                    under the supervision of Prof. <a href="https://zsdonghao.github.io/"> Hao Dong</a>.
                  </p>
                  <p>I just got accpeted by Northwestern M.Sc. in Robotics Program (12 months) and will graduate next year.
                  </p>
                  <p>
                    I completed my Bachelor's degree in 2023 at <a href="https://english.buct.edu.cn/main.htm">BUCT</a>, 
                    where I used to lead the <a href="https://github.com/mvyp/"> SIE Robotics Club</a>.
                  </p>
                  <p>
                    I spent two years at <a href="https://github.com/AIR-DISCOVER">DISCOVER Lab, Tsinghua University</a>, 
                    under the supervision of Prof. <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>, 
                    Prof. <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>, 
                    and Prof. <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>.
                  </p>
                  <p>
                    Proudly, I am a core contributor to 
                    <a href="https://www.kickstarter.com/projects/336477435/mini-pupper-open-sourceros-robot-dog-kit"> Mini Pupper</a>, 
                    an open-source quadruped robot.
                  </p>
                  <p style="text-align:center">
                    <a href="https://www.linkedin.com/in/purimagination/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/0nhc/">GitHub</a> &nbsp;/&nbsp;
                    <a href="https://x.com/serious0nhc">X</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=9vwMTB8AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="mailto:hanzx@u.northwestern.edu">Email</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="index.html">
                    <img 
                    style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" 
                    alt="profile photo" 
                    src="images/favicon/android-chrome-192x192.png" 
                    class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research & Engineering</h2>
                  <p>
                    I have always been working on Robotics. Currently I'm interested in Embodied AI.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="dex_7dof()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dex_7dof' style="opacity: 0;">
                    </div>
                    <img src='images/dex_7dof.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('dex_7dof').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('dex_7dof').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">(Ongoing Project) 7-DOF Humanoid Robotic Arm with Tactile-enabled Dexterous Hand</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://www.linkedin.com/in/jinzhou-l-78001212a/">Jinzhou Li</a>, 
                  <a href="https://ceca.pku.edu.cn/en/people_/faculty_/tao_wang/">Tao Wang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>
                  <p>
                  Constructed a 7-DOF humanoid robotic arm with dexterous hands equipped with tactile sensors for data collection, 
                  and interfaced it with ROS Control and MoveIt. All work was done by me independently.
                  We will work on encoding visual, tactile (not vision-based) and joint signals for imitation learning and deploy learned policies on real robots.
                  </p>
                </td>
              </tr>

              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr onmouseout="active_perception()" onmouseover="bog_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="one">
                        <div class="two" id='active_perception' style="opacity: 0;">
                        </div>
                        <img src='images/active_perception.jpg' width=105%>
                      </div>
                      <script type="text/javascript">
                        function bog_start() {
                          document.getElementById('active_perception').style.opacity = "1";
                        }
    
                        function bog_stop() {
                          document.getElementById('active_perception').style.opacity = "0";
                        }
                        bog_stop()
                      </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <span class="papertitle">(Ongoing Project) Next Best View in Occluded Environments</span>
                      <br>
                      <a href="index.html"><b>Zhengxiao Han</b></a>*, 
                      <a href="index.html"><b>Fei Hu</b></a>*, 
                      <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                      <a href="https://zsdonghao.github.io/">Hao Dong</a>
                      <p>
                      It's challenging for robots to grasp an object with an occluded view. Thus we need a policy to move the gripper to the next 
                      pose for better grasping conditions. We propose to generate a synthetic dataset to train a model predicting the next best view 
                      from the current gripper (eye-on-hand) pose.
                      </p>
                    </td>
                  </tr>

              <!-- <tr onmouseout="tactile_sensor()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='tactile_sensor' style="opacity: 0;">
                    </div>
                    <img src='images/tactile_sensor.jpg' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('tactile_sensor').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('tactile_sensor').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">(Ongoing Project) Vision-based Tactile Sensor</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>
                  <p>
                  Proposed a binocular vision-based tactile sensor. Aiming at utilizing dense markers and binocular 
                  cameras to enhance the accuracy of vision-based tactile sensors.
                  </p>
                </td>
              </tr> -->

              <tr onmouseout="full_stack_6_dof()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='full_stack_6_dof' style="opacity: 0;">
                    </div>
                    <img src='images/full_stack_6_dof.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('full_stack_6_dof').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('full_stack_6_dof').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Full-stack 6-DOF robotic arm development</span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://jiyao06.github.io/">Jiyao Zhang</a>, 
                  <a href="https://zsdonghao.github.io/">Hao Dong</a>	
                  <p>
                  Achived hardware design of a 6-DOF robotic arm and a 2-finger adaptive parallel gripper 
                  (same capability as <a href="https://robotiq.com/products/2f85-140-adaptive-robot-gripper">Robotiq 2f-85 Gripper</a>), 
                  and interfaced all hardware under ROS Control and MoveIt. Interfaced the robotic arm with 
                  <a href="https://graspnet.net/">GraspNet</a> and achived a grasping demo. All work was done by me independently.
                  </p>
                </td>
              </tr>

              <tr onmouseout="bimanual_demonstration()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bimanual_demonstration' style="opacity: 0;">
                    </div>
                    <img src='images/bimanual_demonstration.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('bimanual_demonstration').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('bimanual_demonstration').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.bilibili.com/video/BV1iN411t7eb">Bimanual Demonstration System</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://github.com/ShanningZhuang">Shanning Zhuang</a>, 
                  <a href="http://robotics-tongji.org/members/zihangchen">Zihang Chen</a>, 
                  <a href="https://github.com/GDDG08">Zihan Zhuang</a>, 
                  <a href="http://www.iden.cn/home/active.NewYouzhan/workinfo?sc=yx&id=13012">Ximing Wang</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>
                  <p>
                  Inspired by ALOHA, we proposed an improved bimanual demonstration system. 
                  Constructed the SDK using C++ and CMake. Utilized KDL to solve kinematic and dynamic problems, 
                  then achived gravity compensation based on inverse dynamics. 
                  Designed a parallel two-finger gripper based on rack-gear structures. 
                  </p>
                </td>
              </tr>

              <tr onmouseout="mini_pupper_2()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mini_pupper_2' style="opacity: 0;">
                    </div>
                    <img src='images/mini_pupper_2.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('mini_pupper_2').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('mini_pupper_2').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.kickstarter.com/projects/336477435/mini-pupper-2-open-source-ros2-robot-kit-for-dreamers">Mini Pupper 2: Open-Source Quadruped Robot Dog Kit</a></span>
                  <br>
                  <a href="www.linkedin.com/in/afreez-gan-b606615">Afreez Gan</a>, 
                  <a href="index.html">Lily Wang</a>, 
                  <a href="index.html">Jian Song</a>, 
                  <a href="https://www.linkedin.com/in/marcin-pryli%C5%84ski-a79190249/">Marcin Prylinski</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://github.com/Ericsii">Yunlong Feng</a>
                  <p>
                    Developed all the ROS 2 (Humble) software suite including Locomotion, SLAM, Navigation, and CV functions. 
                    Deployed Cartographer with an Extended Kalman Filter (EKF) to fuse IMU data and LiDAR odometry, 
                    enhancing the robostness and accuracy of Mini Pupper's localization system.
                  </p>
                </td>
              </tr>

              <tr onmouseout="m2sim()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='m2sim' style="opacity: 0;">
                    </div>
                    <img src='images/m2sim.jpg' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('m2sim').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('m2sim').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="data/CICAI_Paper_Camera_Ready.pdf">Long-term Interactive Driving Simulation: MPC to the Rescue</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://scholar.google.com/citations?user=4PXGeaYAAAAJ">Zhijie Yan</a>, 
                  <a href="https://www.linkedin.com/in/yang-li-2000/">Yang Li</a>, 
                  <a href="https://philipflyg.github.io/">Pengfei Li</a>, 
                  <a href="https://scholar.google.com/citations?user=KlHuj2QAAAAJ">Yifeng Shi</a>, 
                  <a href="index.html">Nairui Luo</a>, 
                  <a href="https://scholar.google.com/citations?user=qCbWxzgAAAAJ">Xu Gao</a>, 
                  <a href="https://scholar.google.com/citations?user=alz2MpAAAAAJ">Yongliang Shi</a>, 
                  <a href="index.html">Pengfei Huang</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>, 
                  <a href="https://hangzhaomit.github.io/">Hang Zhao</a>, 
                  <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>
                  </br>
                  <em>CICAI</em>, 2023
                  <p>
                    Cooperated with Baidu Apollo and MARS Lab at Tsinghua University. We propose to introduce a tailored Model Predictive Control 
                    (MPC) module as a rescue into the state-of-the art 
                    interactive trajectory prediction model M2I. Notably, our method can effectively address the Out-of-Domain (OOD) 
                    problem in long-term simulation by enforcing a flexible regularization that admits the replayed data, while still 
                    enjoying the diversity of data-driven predictions.
                  </p>
                </td>
              </tr>

              <tr onmouseout="int2()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='int2' style="opacity: 0;">
                    </div>
                    <img src='images/int2.jpg' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('int2').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('int2').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">
                    <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.html">
                      INT2: Interactive Trajectory Prediction at Intersections
                    </a>
                  </span>
                  <br>
                  <a href="https://scholar.google.com/citations?user=4PXGeaYAAAAJ">Zhijie Yan</a>, 
                  <a href="https://philipflyg.github.io/">Pengfei Li</a>, 
                  <a href="https://scholar.google.com/citations?user=wDMrCnIAAAAJ">Zheng Fu</a>, 
                  <a href="https://daniellli.github.io/">Shaocong Xu</a>, 
                  <a href="https://scholar.google.com/citations?user=alz2MpAAAAAJ">Yongliang Shi</a>, 
                  <a href="https://scholar.google.com/citations?user=_tz64W0AAAAJ">Xiaoxue Chen</a>, 
                  <a href="https://scholar.google.com/citations?user=Wn2Aic0AAAAJ">Yuhang Zheng</a>, 
                  <a href="https://www.linkedin.com/in/yang-li-2000/">Yang Li</a>, 
                  <a href="index.html">Tianyu Liu</a>, 
                  <a href="https://www.linkedin.com/in/lichuxuan/">Chuxuan Li</a>, 
                  <a href="index.html">Nairui Luo</a>, 
                  <a href="https://scholar.google.com/citations?user=qCbWxzgAAAAJ">Xu Gao</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>, 
                  <a href="index.html">Zuoxu Wang</a>, 
                  <a href="https://scholar.google.com/citations?user=KlHuj2QAAAAJ">Yifeng Shi</a>, 
                  <a href="index.html">Pengfei Huang</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1012/1219.htm">Jirui Yuan</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1477.htm">Jiangtao Gong</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>, 
                  <a href="https://hangzhaomit.github.io/">Hang Zhao</a>, 
                  <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>
                  </br>
                  <em>ICCV</em>, 2023
                  <p>
                    We present a large-scale interactive trajectory prediction dataset named INT2 for INTeractive 
                    trajectory prediction at INTersections. INT2 includes 612,000 scenes, each lasting 1 minute, 
                    containing up to 10,200 hours of data. We benchmark the best open-sourced interactive trajectory 
                    prediction method on INT2 and Waymo Open Dataset, under in-domain and cross-domain settings.
                  </p>
                </td>
              </tr>

              <tr onmouseout="multi_robot()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='multi_robot' style="opacity: 0;">
                    </div>
                    <img src='images/multi_robot.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('multi_robot').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('multi_robot').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.youtube.com/watch?v=kmLZ6OmiqrY">Cooperative Multi-Robot System</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="index.html">Jingtian Deng</a>, 
                  <a href="https://linden713.github.io/">Chenghao Lin</a>, 
                  <a href="https://www.linkedin.com/in/tian-ao-ren-2a0349220/">Tianao Ren</a>, 
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>
                  <p>
                    Utilized Pure Pursuit algorithm for multi-robot formation control, which was tested in both real world and Isaac Sim. 
                    Utilized an EKF-based 2D LiDAR localization system as the odometry. 
                    Utilized KDL for solving kinematic problems of our own 6-DOF robotic arm, 
                    and combined it with the odometry, achieving Chiken-Head Mode. 
                    Combined all the functions above, and constructed a multi-robot cooperative system to carry a box in Isaac Sim.
                  </p>
                </td>
              </tr>

              <tr onmouseout="rmus()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='rmus' style="opacity: 0;">
                    </div>
                    <img src='images/rmus.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('rmus').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('rmus').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://youtu.be/7V5SHpF0PHM">ICRA 2022 RoboMaster University Sim2real Challenge</a></span>
                  <br>
                  <a href="index.html"><b>Zhengxiao Han</b></a>, 
                  <a href="https://linden713.github.io/">Chenghao Lin</a>, 
                  <a href="https://www.linkedin.com/in/tian-ao-ren-2a0349220/">Tianao Ren</a>, 
                  <a href="index.html">Luoji Zhu</a>, 
                  <a href="index.html">Haitao Rao</a>
                  <p>
                    Deployed an Extended Kalman Filter (EKF) alongside an omnidirectional motion model for state projection and correction using sensor data, including IMU and odometry.
                    Utilized A* algorithm for global path planning and Timed Elastic Band (TEB) algorithm for local path planning. 
                    Utilized ArUco library for detecting boxes' poses.
                  </p>
                </td>
              </tr>

              <tr onmouseout="mini_pupper()" onmouseover="bog_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mini_pupper' style="opacity: 0;">
                    </div>
                    <img src='images/mini_pupper.gif' width=105%>
                  </div>
                  <script type="text/javascript">
                    function bog_start() {
                      document.getElementById('mini_pupper').style.opacity = "1";
                    }

                    function bog_stop() {
                      document.getElementById('mini_pupper').style.opacity = "0";
                    }
                    bog_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle"><a href="https://www.kickstarter.com/projects/336477435/mini-pupper-open-sourceros-robot-dog-kit">Mini Pupper: Open-Source Quadruped Robot Dog Kit</a></span>
                  <br>
                  <a href="www.linkedin.com/in/afreez-gan-b606615">Afreez Gan</a>, 
                  <a href="https://www.linkedin.com/in/marcin-pryli%C5%84ski-a79190249/">Marcin Prylinski</a>, 
                  <a href="https://twitter.com/tomato5356">Xiongshi Xu</a>, 
                  <a href="index.html"><b>Zhengxiao Han</b></a>
                  <p>
                    Inspired by Stanford's open-source quadruped robot <a href="https://pupper.readthedocs.io/en/latest/">Pupper</a>, I designed my own mechanical hardware, mainly improved its leg structures. 
                    After that, I was contacted by Mini Pupper's team and joined them. We developed the first product together. 
                    I independently developed all the ROS software suite including Locomotion, SLAM, Navigation, and CV functions. 
                    We crowd-funded $500,000 on Kickstarter when I was a junior.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
            
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Education</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <tr>
                <td width="75%" valign="center">
                  <b>Northwestern University, Evanston, Illinois, U.S.A.</b></br>
                  Master of Science, Robotics</br>
                  <em style="color:grey;">2024-2025</em></br>
                </td>
              </tr>
              <tr>
                <td width="75%" valign="center">
                  <b>Beijing University of Chemical Technology, Beijing, China</b></br>
                  Bachelor of Engineering, Mechanical Design, Manufacturing and Its Automation</br>
                  <em style="color:grey;">2019-2023</em></br>
                  GPA: 87.4/100, Ranking: 6/72. Ex-president of <a href="https://github.com/mvyp/"> SIE Robotics Club</a>. Guitar player in the Towers (a student band).
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    June, 2024. </br>
                    Design and source code from <a href="https://github.com/jonbarron/website">Jon Barron's website</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </table>
  </body>
</html>
